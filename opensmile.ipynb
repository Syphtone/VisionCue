{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bb59a1a",
   "metadata": {},
   "source": [
    "This file extracts prosody features such as pitch , loudness and probability of voicing from audio.wav files. And is merged with respective openface features to give a file containing audio and visual features across timeframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa2fb488",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting audio: 100%|██████████| 1/1 [00:01<00:00,  1.11s/it]\n"
     ]
    }
   ],
   "source": [
    "# Convert .mp4 videos to .wav audio files using ffmpeg\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "from tqdm import tqdm\n",
    "\n",
    "video_dir = r\"D:\\RP2\\RP2 Projects\\AI Interview Coach\\UnVid\"\n",
    "wav_dir = r\"D:\\RP2\\RP2 Projects\\AI Interview Coach\\UnVid\\wav\"\n",
    "os.makedirs(wav_dir, exist_ok=True)\n",
    "\n",
    "video_files = [f for f in os.listdir(video_dir) if f.endswith(\".mp4\")]\n",
    "\n",
    "for video in tqdm(video_files, desc=\"Extracting audio\"):\n",
    "    video_path = os.path.join(video_dir, video)\n",
    "    wav_path = os.path.join(wav_dir, os.path.splitext(video)[0] + \".wav\")\n",
    "\n",
    "    command = [\n",
    "        \"ffmpeg\", \"-y\", \"-i\", video_path,\n",
    "        \"-ac\", \"1\", \"-ar\", \"16000\", wav_path\n",
    "    ]\n",
    "    subprocess.run(command, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0111948e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting prosody features: 100%|██████████| 1/1 [00:00<00:00,  3.57it/s]\n"
     ]
    }
   ],
   "source": [
    "# Extract prosody features using OpenSMILE\n",
    "import os\n",
    "import subprocess\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ==== Setup Paths ====\n",
    "opensmile_bin = r\"D:\\RP2\\RP2 Projects\\AI Interview Coach\\opensmile-3.0.2\\bin\\SMILExtract.exe\"\n",
    "opensmile_conf = r\"D:\\RP2\\RP2 Projects\\AI Interview Coach\\opensmile-3.0.2\\config\\prosody\\prosodyShs.conf\"\n",
    "\n",
    "\n",
    "input_dir = r\"D:\\RP2\\RP2 Projects\\AI Interview Coach\\UnVid\\wav\"  # .wav files\n",
    "output_dir = r\"D:\\RP2\\RP2 Projects\\AI Interview Coach\\UnVid\\Testpros\" # .csv output\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# ==== List of files ====\n",
    "video_list = [f for f in os.listdir(input_dir) if f.lower().endswith(\".wav\")]\n",
    "\n",
    "# ==== Loop through all videos ====\n",
    "for file in tqdm(video_list, desc=\"Extracting prosody features\"):\n",
    "    input_path = os.path.join(input_dir, file)\n",
    "    output_path = os.path.join(output_dir, os.path.splitext(file)[0] + \".csv\")\n",
    "\n",
    "    command = [\n",
    "        opensmile_bin,\n",
    "        \"-C\", opensmile_conf,\n",
    "        \"-I\", input_path,\n",
    "        \"-csvoutput\", output_path,\n",
    "        \"-csvoutputdelimiter\", \"comma\",\n",
    "        \"-nologfile\"\n",
    "    ]\n",
    "\n",
    "    result = subprocess.run(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "\n",
    "    if result.returncode != 0:\n",
    "        print(f\"❌ Failed: {file}\")\n",
    "        print(result.stderr.decode())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13fa28bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Merged testsub.csv (907 rows)\n"
     ]
    }
   ],
   "source": [
    "# ===========================================================\n",
    "# Align OpenSMILE audio features with OpenFace video features\n",
    "# ===========================================================\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def align_audio_to_video_folder(audio_folder, video_folder, output_folder):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    audio_files = [f for f in os.listdir(audio_folder) if f.endswith(\".csv\")]\n",
    "    \n",
    "    for file in audio_files:\n",
    "        audio_path = os.path.join(audio_folder, file)\n",
    "        video_path = os.path.join(video_folder, file)\n",
    "        output_path = os.path.join(output_folder, file)\n",
    "        \n",
    "        if not os.path.exists(video_path):\n",
    "            print(f\"⚠️ Skipping {file} (no matching video CSV found)\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # --- Load OpenSMILE prosody CSV (semicolon separator) ---\n",
    "            audio_df = pd.read_csv(audio_path, sep=';')\n",
    "            \n",
    "            # Drop any unnamed columns\n",
    "            audio_df = audio_df.loc[:, ~audio_df.columns.str.contains('^Unnamed')]\n",
    "            \n",
    "            # Detect timestamp column\n",
    "            if 'frameTime' in audio_df.columns:\n",
    "                audio_df.rename(columns={'frameTime': 'timestamp'}, inplace=True)\n",
    "            elif 'time' in audio_df.columns:\n",
    "                audio_df.rename(columns={'time': 'timestamp'}, inplace=True)\n",
    "            else:\n",
    "                # Try to find any column with 'time' in the name (case-insensitive)\n",
    "                time_cols = [col for col in audio_df.columns if 'time' in col.lower()]\n",
    "                if time_cols:\n",
    "                    audio_df.rename(columns={time_cols[0]: 'timestamp'}, inplace=True)\n",
    "                    print(f\"ℹ️ {file}: Using '{time_cols[0]}' as timestamp column\")\n",
    "                else:\n",
    "                    print(f\"❌ {file}: No timestamp column found in audio CSV\")\n",
    "                    print(f\"   Available columns: {list(audio_df.columns)}\")\n",
    "                    continue\n",
    "            \n",
    "            # Drop 'name' if exists\n",
    "            if 'name' in audio_df.columns:\n",
    "                audio_df.drop(columns=['name'], inplace=True)\n",
    "            \n",
    "            # --- Load OpenFace CSV ---\n",
    "            video_df = pd.read_csv(video_path)\n",
    "            \n",
    "            # Detect timestamp column in video\n",
    "            if 'timestamp' not in video_df.columns:\n",
    "                if 'frame' in video_df.columns or 'Frame' in video_df.columns:\n",
    "                    # Try to use frame column\n",
    "                    frame_col = 'frame' if 'frame' in video_df.columns else 'Frame'\n",
    "                    video_df.rename(columns={frame_col: 'timestamp'}, inplace=True)\n",
    "                else:\n",
    "                    video_df.rename(columns={video_df.columns[0]: 'timestamp'}, inplace=True)\n",
    "            \n",
    "            # Convert timestamps to float\n",
    "            audio_df['timestamp'] = pd.to_numeric(audio_df['timestamp'], errors='coerce')\n",
    "            video_df['timestamp'] = pd.to_numeric(video_df['timestamp'], errors='coerce')\n",
    "            \n",
    "            # Drop invalid timestamps\n",
    "            audio_df.dropna(subset=['timestamp'], inplace=True)\n",
    "            video_df.dropna(subset=['timestamp'], inplace=True)\n",
    "            \n",
    "            # Ensure timestamp columns exist and have data\n",
    "            if audio_df.empty or video_df.empty:\n",
    "                print(f\"❌ {file}: Empty timestamp data after cleaning, skipping\")\n",
    "                continue\n",
    "            \n",
    "            # Round to 3 decimals\n",
    "            audio_df['timestamp'] = audio_df['timestamp'].round(3)\n",
    "            video_df['timestamp'] = video_df['timestamp'].round(3)\n",
    "            \n",
    "            # Remove duplicate timestamps in video (keep first)\n",
    "            video_df = video_df.drop_duplicates(subset=['timestamp'], keep='first')\n",
    "            \n",
    "            # --- Align audio → video using merge_asof (nearest match) ---\n",
    "            # Sort both dataframes by timestamp\n",
    "            audio_df = audio_df.sort_values('timestamp').reset_index(drop=True)\n",
    "            video_df = video_df.sort_values('timestamp').reset_index(drop=True)\n",
    "            \n",
    "            # Use merge_asof for nearest timestamp matching\n",
    "            merged = pd.merge_asof(\n",
    "                video_df,\n",
    "                audio_df,\n",
    "                on='timestamp',\n",
    "                direction='nearest',\n",
    "                tolerance=0.1  # Max 100ms difference\n",
    "            )\n",
    "            \n",
    "            # Save the result\n",
    "            merged.to_csv(output_path, index=False)\n",
    "            print(f\"✅ Merged {file} ({len(merged)} rows)\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing {file}: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "\n",
    "# Example usage:\n",
    "# align_audio_to_video_folder('audio_csvs', 'video_csvs', 'merged_output')\n",
    "\n",
    "\n",
    "align_audio_to_video_folder(\n",
    "    audio_folder=r\"D:\\RP2\\RP2 Projects\\AI Interview Coach\\UnVid\\Testpros\",\n",
    "    video_folder=r\"D:\\RP2\\RP2 Projects\\AI Interview Coach\\UnVid\\openface_results\\csv\",\n",
    "    output_folder=r\"D:\\RP2\\RP2 Projects\\AI Interview Coach\\UnVid\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa75e0c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
